{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bf949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "First row of the tensor:\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# tensors\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "print(\"First row of the tensor:\")\n",
    "print(tensor[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30e1ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Addition:\n",
      "tensor([[2, 4],\n",
      "        [6, 8]])\n",
      "Tensor Multiplication:\n",
      "tensor([[ 1,  4],\n",
      "        [ 9, 16]])\n",
      "Tensor Matrix Multiplication:\n",
      "tensor([[ 7, 10],\n",
      "        [15, 22]])\n"
     ]
    }
   ],
   "source": [
    "#operations\n",
    "tensor_add = tensor +tensor\n",
    "tensor_mul = tensor * tensor\n",
    "tensor_matmul = torch.matmul(tensor, tensor)\n",
    "print(\"Tensor Addition:\")\n",
    "print(tensor_add)\n",
    "print(\"Tensor Multiplication:\")\n",
    "print(tensor_mul)\n",
    "print(\"Tensor Matrix Multiplication:\")\n",
    "print(tensor_matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72eea45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of y with respect to x: tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "#automatic differentiation\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "#compute backward\n",
    "y.backward()\n",
    "print(\"Gradient of y with respect to x:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f0ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 6 samples\n",
      "\n",
      "\n",
      "Sample batch: \n",
      "\n",
      "X: tensor([[4.5000, 5.0000, 5.5000],\n",
      "        [0.5000, 1.0000, 1.5000]]) \n",
      "\n",
      "Y: tensor([6., 2.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Generating a simple example dataset dataframe\n",
    "data = {\n",
    "    \"feature1\": [0.5, 1.5, 2.5, 3.5, 4.5, 6.0],\n",
    "    \"feature2\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "    \"feature3\": [1.5, 2.5, 3.5, 4.5, 5.5, 7.0],\n",
    "    \"target\": [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = dataframe.drop(\"target\", axis=1).values\n",
    "        self.targets = dataframe[\"target\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return features, target\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CustomDataset(df)\n",
    "print(f\"The dataset has {len(dataset)} samples\")\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Checking one batch of the dataloader\n",
    "dataiter = iter(dataloader)\n",
    "sample_X, sample_y = next(dataiter)\n",
    "print(f\"\\n\\nSample batch: \\n\\nX: {sample_X} \\n\\nY: {sample_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44e3d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Declaring the layers to use\n",
    "        self.fc1 = nn.Linear(3, 2)        # input layer (3 inputs, 2 hidden neurons)\n",
    "        self.fc2 = nn.Linear(2, 1)        # output layer (2 hidden neurons, 1 output target)\n",
    "        self.relu = nn.ReLU()            # ReLu activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defining the connections and data flow across layers in the model\n",
    "        # (2 inputs, 4 hidden neurons + ReLu, 1 output target)\n",
    "        x = self.fc1(x)               # input to hidden\n",
    "        x = self.relu(x)             # activation\n",
    "        x = self.fc2(x)               # hidden to output\n",
    "        return x                    # output\n",
    "\n",
    "# Instantiate the network\n",
    "model = SimpleNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc33cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Defining a Loss Function, we use the Mean Squared Error in this case\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Defining an Optimizer function, we use Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005)       # learning rate of 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4100bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 1 ----\n",
      "Batch 1, Loss: 20.87030029296875\n",
      "Batch 2, Loss: 5.47598934173584\n",
      "Batch 3, Loss: 7.932060718536377\n",
      "---- Epoch 2 ----\n",
      "Batch 1, Loss: 3.696017265319824\n",
      "Batch 2, Loss: 0.8965308666229248\n",
      "Batch 3, Loss: 0.5468356609344482\n",
      "---- Epoch 3 ----\n",
      "Batch 1, Loss: 0.16841799020767212\n",
      "Batch 2, Loss: 0.13174627721309662\n",
      "Batch 3, Loss: 0.27956822514533997\n",
      "---- Epoch 4 ----\n",
      "Batch 1, Loss: 0.21821948885917664\n",
      "Batch 2, Loss: 0.19246964156627655\n",
      "Batch 3, Loss: 0.20340344309806824\n",
      "---- Epoch 5 ----\n",
      "Batch 1, Loss: 0.16279704868793488\n",
      "Batch 2, Loss: 0.033678460866212845\n",
      "Batch 3, Loss: 0.29013609886169434\n",
      "---- Epoch 6 ----\n",
      "Batch 1, Loss: 0.10524575412273407\n",
      "Batch 2, Loss: 0.15835218131542206\n",
      "Batch 3, Loss: 0.09529048949480057\n",
      "---- Epoch 7 ----\n",
      "Batch 1, Loss: 0.05466783419251442\n",
      "Batch 2, Loss: 0.05647894740104675\n",
      "Batch 3, Loss: 0.3463205099105835\n",
      "---- Epoch 8 ----\n",
      "Batch 1, Loss: 0.1902540922164917\n",
      "Batch 2, Loss: 0.062352925539016724\n",
      "Batch 3, Loss: 0.37042754888534546\n",
      "---- Epoch 9 ----\n",
      "Batch 1, Loss: 0.17309752106666565\n",
      "Batch 2, Loss: 0.1991000473499298\n",
      "Batch 3, Loss: 0.1736021637916565\n",
      "---- Epoch 10 ----\n",
      "Batch 1, Loss: 0.07539257407188416\n",
      "Batch 2, Loss: 0.293172687292099\n",
      "Batch 3, Loss: 0.1728852093219757\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    print(f\"---- Epoch {epoch+1} ----\")\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(X).squeeze()  # Forward pass\n",
    "        loss = criterion(outputs, y)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        print(f\"Batch {batch+1}, Loss: {loss}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a160bf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 4060 Laptop GPU'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69fed4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "New sample: tensor([2., 3., 3.], device='cuda:0')\n",
      "Prediction: tensor(3.1472, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Creating a new sample \n",
    "new_X = torch.tensor([2., 3., 3.])\n",
    "\n",
    "# Move tensor to GPU\n",
    "new_X = new_X.to(device)\n",
    "print(\"New sample:\", new_X)\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Inference from GPU\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(new_X)\n",
    "    \n",
    "print(\"Prediction:\", pred[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
